## 정형 데이터와 비정형 데이터를 처리하는 기술의 차이점과 각각의 실용 사례를 설명하시오.

정형데이터의 핵심은 고정된 구조입니다. 보통 명시된 데이터를 sql이나 엑셀에 저장하는게 일반적입니다.
그렇다면 정형데이터를 처리하는데 가장 중요한 것은 뭘까요? 바로 전처리 작업입니다.
본격적으로 데이터 프레임을 만지고 RDBS에 저장하기전에 제대로 가공 할 필요가 있는 것입니다.

예시를 들어드리겠습니다. 캡스톤을 진행 할 때 저는 데이터 크롤링과 벡엔드 데이터 처리를 맡았습니디.
강원도 여행지의 식당과 카페 여행지 정보들을 모아놓은 수많은 정형 데이터를 전처리 해 RDBS에 넣고
관리를 했습니다. 당시 저는 멍청하게도 이 전처리 과정에서 판다스를 이용할 생각을 하지 못했습니다.
가공되지 않은 많은 정형데이터를 하나하나 엑셀에서 전처리 해나갔죠. 시간이 많이 소모 되었습니다.

```python
df_selected = df_csv[['이름', '오픈시간', '휴일']]
df_selected.fillna('없음', inplace=True) 
```

이 때 제가 팬더스의 .select와 .fillna() 내장함수를 썻다면 어땠을까요. 오픈시간,휴일,가격정보가
없는 곳의 결측치를 빠르게 채울 수 있었겠죠. 이후에 각 식당의 리뷰 평점을 모아 .mean()을 먹여서
유의미한 평균 평점 정보도 제공할 수 있었을 겁니다. 

![KakaoTalk_Photo_2025-02-14-14-34-43.png](attachment:c2334ce2-8442-404a-b0bb-8a632cb111da:KakaoTalk_Photo_2025-02-14-14-34-43.png)

비정형데이터는 텍스트만으로 표현되는 정형데이터 보다 더 많은 정보를 제공하기 위해 쓰이고 있습니다.
텍스트를 포함,이미지,오디오 까지 들어갈 수 있습니다.
이것들을 아마 우리들은 클라우드상에서 각종 로그들은 api로 받아와 json으로 처리하는 작업,
학습시킨 모델을 쿠버네티스상에서 배포하기 위해 yaml을 쓰는 방법을 주로 쓰게 될 것 같습니다.
특히 우리가 앞으로 모델 개발을 배우는 과정에서 yaml파일은 필연적으로 많이 쓰리게 되는것 같습니다.
모델을 재사용 하기위해서 정보값들을 yaml파일로 저장해 놓는다면 우리는 파이썬에서 이 파일을 불러와 모델의 설정을 쉽게 적용 할 수 있습니다. 

```yaml
model:
name: "transformer"
layers: 12
hidden_size: 768
dropout: 0.1
training:
batch_size: 32
learning_rate: 0.0001
epochs: 10
```

```python
import yaml

with open("config.yaml", "r") as file:
config = yaml.safe_load(file)
model_name = config["model"]["name"]
batch_size = config["training"]["batch_size"]
print(f"Model: {model_name}, Batch Size: {batch_size}")
```

비정형 데이터 전처리에서 가장 중요한 것은 

```python
clean_text = re.sub(r"[^a-zA-Z0-9\s]", "", text_data)
```

.sub() 내장함수라고 생각 듭니다. 파일을 불러와 분석하기 전 특수문자들을 지워주는 유용한 코드입니다.

```python
df.to_csv("api_posts.csv", index=False, encoding='utf-8')
```

캡스톤에서 모든 엑셀파일을 json으로 변환하는 과정에서 또 하나하나 이 인코딩을 바꾸는데 손품이 정말 많이 들어 넣어 보았습니다. ㅜㅜ

감사합니다.
