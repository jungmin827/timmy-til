모델 학습시에 최적의 손실함수를 찾는 과정 -> 국소최적해를 넘어 글로벌한 최솟값을 찾아야함.

모델의 일부를 분리해 검증데이터로 예측을 수행한다. 9:1 -> 900개로 학습하고 100개로 검증.

사전 훈련 모델: 내가 모델을 생성하더라도 사전훈련모델을 사용하면 더욱 빠른 학습이 가능하다.
케라스에서의 모델 컴파일: 옵티마이저, 손실함수,모델 레이어, 순전파를 모델 선언과정에서 정의 한다.

잔차 신경망..? 예측값과 실제값의 오차를 학습하는 구조로 성능을 향상시키는 모델 결국 깊은 신경망으로 들어갈수록 기울기가 아주 소실되기 때문에

더블클릭 또는 Enter 키를 눌러 수정

**트랜스퍼 러닝: 사전훈련된 모델을 일단 사용하고 이것을 추가로 튜닝하는것임. 결국 사전훈련된 파라미터들을 사용하는것임. 각 주제에 가장 성능이 좋은 모델을 사용할 수 있음. 그리고 자신의 주제에 맞게 커스텀을 함. 그대로 썻는데 내 문제에서 성능이 안나온다? -> 앙상블?,혹은 새모델 탐색

파인튜닝: 기존 모델의 재훈련, 최적화. 미세 조정을 함. -> 기존의 모델과 내 주제가 다를 때 필요

특징 추출: 결국 중간계층 가중치는 그대로 쓰고 마지막 분류레이어만 새로 학습


## 코드적으로 익숙해질 필요가 있다.
